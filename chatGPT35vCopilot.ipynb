{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVE\n",
    "To check if LLMs can detect data leaks in our code\n",
    "\n",
    "# Approach\n",
    "Create a sample code of logistic regression on titanic dataset. Intentionally include data leak in scaling feature i.e scale on entire dataset at once. The correct approach would be to first split the data into train-test and then scale seperately. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following prompt was fed to both OPEN AI CHAT GPT 3.5 and Microsoft Copilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"review the code for any data leaks\"\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Titanic dataset\n",
    "url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Data preprocessing\n",
    "titanic_data = titanic_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n",
    "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
    "titanic_data = titanic_data.dropna()\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = titanic_data.drop('Survived', axis=1)\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Scale the features. Intentionally introducing data leak.\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the scaled data into training and testing sets. Correct approach would be first split then scale separately. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that the comments are only for our understanding. All comments were omitted and the prompt code did not have any comments in it. I wanted to see if AI could figure out the objective of the code itself and then identify the data leak."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CHAT GPT Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided code looks well-structured, and I don't see any explicit data leakage. However, to ensure there is no unintentional data leakage, let's go through the code:\n",
    "\n",
    "1. **Data Loading:**\n",
    "   - The code loads the data directly from an external URL. This is generally fine as long as the data is publicly available and consistent over time. However, it's worth noting that if the external data source changes or is updated, it might affect the results of your analysis.\n",
    "\n",
    "2. **Feature Selection:**\n",
    "   - The features selected for training the model (`'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived'`) seem appropriate for a basic analysis of Titanic survival. Ensure that there are no features used in the model that would not be available at the time of prediction.\n",
    "\n",
    "3. **Data Transformation:**\n",
    "   - The 'Sex' column is transformed to numeric values, which is a common practice. However, if you later plan to deploy this model and use it in a real-world scenario, ensure that the encoding is consistent with what you expect when new data is provided.\n",
    "\n",
    "4. **Handling Missing Values:**\n",
    "   - Missing values are dropped from the dataset using `titanic_data = titanic_data.dropna()`. It's essential to be aware of the impact of this decision. If there are missing values in the test set during deployment, you'll need to handle them in a way consistent with what you did during training.\n",
    "\n",
    "5. **Scaling:**\n",
    "   - Features are scaled using `StandardScaler()`, which is a good practice for many machine learning models. Just ensure that the scaler is fit on the training data and applied consistently to both training and test sets to prevent data leakage.\n",
    "\n",
    "6. **Train-Test Split:**\n",
    "   - The train-test split is performed using `train_test_split` with a specified random seed (`random_state=42`). This ensures reproducibility, which is good. However, always be cautious with the choice of the random seed, and consider whether the chosen seed might affect the results.\n",
    "\n",
    "7. **Model Training and Evaluation:**\n",
    "   - The logistic regression model is trained on the training set and evaluated on the test set. There doesn't seem to be any explicit data leakage in this process.\n",
    "\n",
    "In summary, while the code appears well-written and doesn't contain obvious data leakage, it's always a good practice to be mindful of the data sources, transformations, and preprocessing steps to ensure that your model is trained and evaluated correctly. Consider documenting your data processing steps and testing the model with new, unseen data to ensure its generalizability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "### Surprising!\n",
    "Its so surpising that the it explicitly mentions \"ensure that the scaler is fit on the training data and applied consistently to both training and test sets to prevent data leakage.\" but still is unable to identify the exact same issue in our code. This should not be happening in my opinion.\n",
    "\n",
    "So I followed up with \"there is data leak try again\"\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Apologies for any confusion in my previous responses. I've reviewed the code again, and I see a potential issue with data leakage in the following line:\n",
    "\n",
    "```python\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "```\n",
    "\n",
    "The `fit_transform` method is used, which means the `StandardScaler` is fit on the entire dataset `X` and then applied to transform it. This can lead to data leakage because the scaler is supposed to be fitted only on the training data to avoid introducing information from the test set into the training process.\n",
    "\n",
    "To address this potential data leakage, you should fit the scaler on the training set and then use the same scaler to transform both the training and test sets. Here's how you can modify that part of the code:\n",
    "\n",
    "```python\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "This modification ensures that the scaler is fit only on the training data (`X_train`) and then applied to both the training and test sets (`X_test`). This way, information from the test set doesn't influence the scaling process during training, eliminating the risk of data leakage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "Immediately it identified the data leaks and further suggested methods to overcome the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copilot Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your code appears to be well-structured and free from obvious data leaks. Let's break down the key steps:\n",
    "\n",
    "1. **Data Preparation**:\n",
    "   - You've loaded the Titanic dataset from Stanford's archive.\n",
    "   - You've selected relevant features: 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', and 'Survived'.\n",
    "   - You've mapped the 'Sex' column to numerical values (0 for male, 1 for female).\n",
    "   - You've dropped rows with missing values (NaN) from the dataset.\n",
    "\n",
    "2. **Feature Scaling**:\n",
    "   - You've standardized the features using `StandardScaler`.\n",
    "\n",
    "3. **Train-Test Split**:\n",
    "   - You've split the data into training and testing sets.\n",
    "\n",
    "4. **Logistic Regression Model**:\n",
    "   - You've created a logistic regression model using `LogisticRegression`.\n",
    "   - The model has been trained on the training data.\n",
    "\n",
    "5. **Model Evaluation**:\n",
    "   - You've made predictions on the test set using `predict`.\n",
    "   - The accuracy of the model on the test data is printed.\n",
    "   - The confusion matrix and classification report provide additional evaluation metrics.\n",
    "\n",
    "Remember to continue testing your model on unseen data and consider cross-validation to assess its generalization performance. Great job! 🚀👩‍💻👨‍💻 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No comments from copilot related to data leakage. So here also I followed up with \" there is data leak try again\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I apologize for the oversight. Thank you for pointing it out. Upon reviewing the code again, I've identified the data leak. The issue lies in the **feature scaling** step. Specifically, the `StandardScaler` should be fit on the **training data only**, and then applied to both the training and test data. Here's the corrected version of your code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "url = \"https://web.stanford.edu/class/archive/cs/cs109/cs109.1166/stuff/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "titanic_data = titanic_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Survived']]\n",
    "titanic_data['Sex'] = titanic_data['Sex'].map({'male': 0, 'female': 1})\n",
    "titanic_data = titanic_data.dropna()\n",
    "\n",
    "X = titanic_data.drop('Survived', axis=1)\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Corrected: Fit the scaler on the training data only\n",
    "scaler = StandardScaler()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "print(f\"Classification Report:\\n{classification_rep}\")\n",
    "```\n",
    "\n",
    "This corrected version ensures that the scaling is applied consistently to both the training and test data, preventing any data leakage. Thank you for your attention, and happy coding! 🚀👩‍💻👨‍💻 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TLDR- both LLMs failed to identify the data leaks on its own. They were able to detect data leak only after explicitly mentioning that there is a data leak. Maybe we should start using the prompt “there is an error try again” as a fool proof check. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
